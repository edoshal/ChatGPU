// Chat Page

let currentSessionId = null;
let chatMessages = [];

function resizeChatLayout() {
    const card = document.querySelector('.chat-card');
    const cardBody = card ? card.querySelector('.card-body') : null;
    const messages = document.getElementById('chat-messages');
    const inputArea = document.getElementById('chat-input-area');
    if (!cardBody || !messages || !inputArea) return;

    // T√≠nh chi·ªÅu cao c√≤n l·∫°i d·ª±a tr√™n viewport ƒë·ªÉ lu√¥n nh√¨n th·∫•y input
    const bodyTop = cardBody.getBoundingClientRect().top;
    const viewportHeight = window.innerHeight || document.documentElement.clientHeight;
    const inputHeight = inputArea.offsetHeight;
    const verticalPadding = 24; // buffer
    const available = Math.max(140, viewportHeight - bodyTop - inputHeight - verticalPadding);

    messages.style.height = `${available}px`;
    messages.style.maxHeight = `${available}px`;
}

async function renderChat() {
    const { $, api, currentProfile } = window.__APP__;
    const profile = currentProfile();

    const container = $('#page-container');
    container.style.padding = '2rem';
    container.style.background = 'rgba(255, 255, 255, 0.95)';
    // G·∫Øn class chuy√™n d·ª•ng cho trang chat ƒë·ªÉ ki·ªÉm so√°t scroll
    container.classList.add('chat-page');

    if (!profile) {
        container.innerHTML = `
            <div class="text-center mt-4">
                <i class="fas fa-user-circle" style="font-size: 4rem; color: #667eea;"></i>
                <h2>Ch∆∞a ch·ªçn h·ªì s∆° s·ª©c kh·ªèe</h2>
                <p class="text-muted">Vui l√≤ng ch·ªçn ho·∫∑c t·∫°o h·ªì s∆° s·ª©c kh·ªèe ƒë·ªÉ b·∫Øt ƒë·∫ßu t∆∞ v·∫•n</p>
                <a href="#/profiles" class="btn btn-primary">
                    <i class="fas fa-arrow-right"></i>
                    ƒê·∫øn trang h·ªì s∆°
                </a>
            </div>
        `;
        return;
    }

    container.innerHTML = `
        <div class="card-header">
            <h3 class="card-title">
                <i class="fas fa-robot"></i>
                Tr·ª£ l√Ω t∆∞ v·∫•n s·ª©c kh·ªèe
            </h3>
            <small class="text-muted">H·ªèi v·ªÅ th·ª±c ph·∫©m ho·∫∑c chia s·∫ª t√¨nh tr·∫°ng s·ª©c kh·ªèe c·ªßa b·∫°n</small>
        </div>
        <div class="card-body" style="flex: 1; display: flex; flex-direction: column; height: calc(100% - 30px);">
            <div id="chat-messages" style="flex: 1; overflow-y: auto; margin-bottom: 1rem; padding: 1rem; background: #f8f9fa; border-radius: 8px;">
                <div class="chat-message bot-message">
                    <div class="message-avatar">
                        <i class="fas fa-robot"></i>
                    </div>
                    <div class="message-content">
                        <strong>Tr·ª£ l√Ω s·ª©c kh·ªèe</strong>
                        <p>Xin ch√†o! T√¥i l√† chuy√™n gia t∆∞ v·∫•n s·ª©c kh·ªèe v√† dinh d∆∞·ª°ng c·ªßa b·∫°n. T√¥i c√≥ th·ªÉ:</p>
                        <ul>
                            <li><strong>T∆∞ v·∫•n th·ª±c ph·∫©m:</strong> ƒê√°nh gi√° m·ªçi lo·∫°i th·ª±c ph·∫©m d·ª±a tr√™n t√¨nh tr·∫°ng s·ª©c kh·ªèe c·ªßa b·∫°n</li>
                            <li><strong>C·∫≠p nh·∫≠t h·ªì s∆°:</strong> T·ª± ƒë·ªông ghi nh·∫≠n th√¥ng tin s·ª©c kh·ªèe m·ªõi b·∫°n chia s·∫ª</li>
                            <li><strong>Khuy·∫øn ngh·ªã c·ª• th·ªÉ:</strong> L∆∞·ª£ng ƒÉn, c√°ch ch·∫ø bi·∫øn, th·ªùi ƒëi·ªÉm ph√π h·ª£p</li>
                            <li><strong>Th·ª±c ph·∫©m ƒë·∫∑c bi·ªát:</strong> Tra c·ª©u m√≥n ƒÉn ƒë·ªãa ph∆∞∆°ng/ƒë·∫∑c s·∫£n khi c·∫ßn</li>
                        </ul>
                        <p><em>V√≠ d·ª•: "T√¥i b·ªã ti·ªÉu ƒë∆∞·ªùng, c√≥ n√™n ƒÉn chu·ªëi kh√¥ng?" ho·∫∑c "T√¥i v·ª´a tƒÉng 2kg trong th√°ng n√†y"</em></p>
                    </div>
                </div>
            </div>
            <div id="chat-input-area">
                <div id="image-preview" style="display: none; margin-bottom: 0.5rem;">
                    <div style="position: relative; display: inline-block;">
                        <img id="preview-image" style="max-width: 200px; max-height: 150px; border-radius: 8px; border: 1px solid #ddd;">
                        <button id="remove-image" style="position: absolute; top: -8px; right: -8px; background: #dc3545; color: white; border: none; border-radius: 50%; width: 24px; height: 24px; font-size: 12px; cursor: pointer;" type="button">√ó</button>
                    </div>
                </div>
                <div id="chat-form" class="input-group">
                    <button id="voice-button" class="btn" title="B·∫≠t ch·∫ø ƒë·ªô chat gi·ªçng n√≥i" type="button">
                        <i class="fas fa-microphone"></i>
                    </button>
                    <input type="text" id="chat-input" class="form-control" placeholder="Nh·∫≠p tin nh·∫Øn ho·∫∑c ·∫•n ƒë√® n√∫t mic ƒë·ªÉ ghi √¢m..." autocomplete="off">
                    <input type="file" id="image-upload" accept="image/*" style="display: none;">
                    <button id="image-button" class="btn btn-secondary" title="T·∫£i ·∫£nh th·ª±c ph·∫©m" type="button">
                        <i class="fas fa-camera"></i>
                    </button>
                    <button id="send-button" class="btn btn-primary" type="button">
                        <i class="fas fa-paper-plane"></i>
                    </button>
                </div>
                <div id="typing-indicator" style="display: none; margin-top: 0.5rem; color: #6c757d;">
                    <small><i class="fas fa-circle-notch fa-spin"></i> Tr·ª£ l√Ω ƒëang so·∫°n tin nh·∫Øn...</small>
                </div>
            </div>
        </div>
    `;

    // Load existing chat session (retry once if needed)
    await loadChatSession();
    if (!currentSessionId) {
        await new Promise(r => setTimeout(r, 200));
        await loadChatSession();
    }

    // Setup event listeners
    setupChatEventListeners();

    // Debug log
    console.log('Chat input element:', document.getElementById('chat-input'));
    console.log('Send button element:', document.getElementById('send-button'));
    console.log('Image button element:', document.getElementById('image-button'));

    // Resize layout ƒë·ªÉ b·∫£o ƒë·∫£m √¥ nh·∫≠p lu√¥n hi·ªÉn th·ªã
    resizeChatLayout();
    window.addEventListener('resize', resizeChatLayout);
}

async function loadChatSession() {
    const { api, currentProfile } = window.__APP__;
    const profile = currentProfile();

    try {
        // Get existing chat sessions
        const sessions = await api(`/api/profiles/${profile.id}/chats`);

        if (sessions.length === 0) {
            // Create new session (correct POST usage)
            const newSession = await api(`/api/profiles/${profile.id}/chats`, {
                method: 'POST'
            });
            currentSessionId = newSession.session_id;
        } else {
            currentSessionId = sessions[0].id;
        }

        // Guard: ensure we have a valid session id before requesting messages
        if (!currentSessionId) {
            console.warn('Chat session ch∆∞a s·∫µn s√†ng. S·∫Ω th·ª≠ l·∫°i sau.');
            return;
        }

        // Load messages for the session
        const messages = await api(`/api/chats/${currentSessionId}/messages`);
        chatMessages = Array.isArray(messages) ? messages : [];
        displayMessages();

    } catch (error) {
        console.error('Error loading chat session:', error);
    }
}

function displayMessages() {
    const messagesContainer = document.getElementById('chat-messages');
    if (!messagesContainer) return;

    // Keep the welcome message and add chat history
    const welcomeMessage = messagesContainer.querySelector('.bot-message');
    messagesContainer.innerHTML = '';
    messagesContainer.appendChild(welcomeMessage);

    chatMessages.forEach(msg => {
        const messageEl = createMessageElement(msg);
        messagesContainer.appendChild(messageEl);
    });

    // Scroll to bottom
    messagesContainer.scrollTop = messagesContainer.scrollHeight;
}

function createMessageElement(message) {
    const { create } = window.__APP__;
    const isUser = (message.role === 'user') || (message.message_type === 'user'); // fallback c≈©
    const hasImage = message.metadata && message.metadata.has_image;

    const contentChildren = [];

    // Image (n·∫øu c√≥)
    if (hasImage && message.metadata.image_data) {
        contentChildren.push(
            create('img', {
                className: 'chat-image',
                src: `data:image/jpeg;base64,${message.metadata.image_data}`,
                onclick: () => {
                    const newTab = window.open();
                    newTab.document.write(`<img src=\"data:image/jpeg;base64,${message.metadata.image_data}\" style=\"max-width:100%;height:auto\">`);
                }
            })
        );
    }

    // Text v·ªõi icon ƒë·∫∑c bi·ªát cho voice message
    if (message.content) {
        const textDiv = create('div', {
            className: 'chat-text',
            innerHTML: formatMessageContent(message.content)
        });

        // Th√™m icon microphone cho voice messages
        if (message.auto_play_response || message.metadata?.voice_input) {
            const voiceIcon = create('i', {
                className: 'fas fa-microphone voice-message-icon',
                title: 'Tin nh·∫Øn b·∫±ng gi·ªçng n√≥i'
            });
            textDiv.insertBefore(voiceIcon, textDiv.firstChild);
        }

        contentChildren.push(textDiv);
    }

    // Th√™m n√∫t TTS cho tin nh·∫Øn assistant c√≥ text
    if (!isUser && message.content && message.content.trim()) {
        contentChildren.push(
            create('div', { className: 'tts-controls' }, [
                // MMS-TTS-VIE button (Blue sound icon)
                create('button', {
                    className: 'tts-button mms-tts-button',
                    type: 'button',
                    onclick: (event) => playTextAsAudioMMS(message.content, event),
                    title: 'Ph√°t audio (Facebook MMS-TTS-VIE)'
                }, [
                    create('i', { className: 'fas fa-volume-up' })
                ]),
                // Azure TTS button (original)
                create('button', {
                    className: 'tts-button azure-tts-button',
                    type: 'button',
                    onclick: (event) => playTextAsAudio(message.content, event),
                    title: 'Ph√°t audio (Azure)'
                }, [
                    create('i', { className: 'fas fa-volume-up' })
                ])
            ])
        );
    }

    const bubble = create('div', { className: `chat-bubble ${isUser ? 'user' : 'assistant'}` }, contentChildren);

    return create('div', { className: `chat-message ${isUser ? 'user' : 'assistant'}` }, [
        ...((!isUser) ? [create('div', { className: 'chat-avatar assistant' }, [ create('i', { className: 'fas fa-robot' }) ])] : []),
        bubble,
        ...(isUser ? [create('div', { className: 'chat-avatar user' }, [ create('i', { className: 'fas fa-user' }) ])] : [])
    ]);
}

function formatMessageContent(content) {
    // Basic formatting for AI responses
    return content
        .replace(/\*\*(.*?)\*\*/g, '<strong>$1</strong>')  // Bold
        .replace(/\*(.*?)\*/g, '<em>$1</em>')              // Italic
        .replace(/\n/g, '<br>')                            // Line breaks
        .replace(/(\d+)\.\s/g, '<br>$1. ')                 // Numbered lists
        .replace(/- (.*?)(<br>|$)/g, '<br>‚Ä¢ $1$2');        // Bullet points
}

// Bi·∫øn global ƒë·ªÉ qu·∫£n l√Ω audio
let currentAudio = null;
let currentTTSButton = null;

// Bi·∫øn global ƒë·ªÉ qu·∫£n l√Ω voice chat - Press & Hold mode
let isRecording = false;
let mediaRecorder = null;
let audioChunks = [];
let isPressedDown = false;

async function playTextAsAudio(text, event) {
    // NgƒÉn ch·∫∑n default action v√† event propagation
    if (event) {
        event.preventDefault();
        event.stopPropagation();
        event.stopImmediatePropagation();
    }
    
    const { api } = window.__APP__;
    
    // T√¨m button ƒë∆∞·ª£c click (event target)
    const button = event ? event.target.closest('.tts-button') : null;
    if (!button) return;

    // N·∫øu ƒëang ph√°t audio n√†y, th√¨ d·ª´ng
    if (currentAudio && currentTTSButton === button) {
        currentAudio.pause();
        currentAudio = null;
        currentTTSButton = null;
        button.innerHTML = '<i class="fas fa-volume-up"></i>';
        button.disabled = false;
        button.title = 'Ph√°t audio';
        return;
    }

    // D·ª´ng audio kh√°c n·∫øu ƒëang ph√°t
    if (currentAudio && currentTTSButton) {
        currentAudio.pause();
        currentAudio = null;
        currentTTSButton.innerHTML = '<i class="fas fa-volume-up"></i>';
        currentTTSButton.disabled = false;
        currentTTSButton.title = 'Ph√°t audio';
    }

    try {
        // Hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang t·∫°o audio
        button.innerHTML = '<i class="fas fa-circle-notch fa-spin"></i>';
        button.disabled = true;
        button.title = 'ƒêang t·∫°o √¢m thanh...';

        // G·ªçi API ƒë·ªÉ t·∫°o audio
        const response = await api('/api/tts/generate', {
            method: 'POST',
            body: JSON.stringify({ text: text }),
            noLoading: true  // Kh√¥ng hi·ªÉn th·ªã loading global
        });

        if (response.success && response.audio_data_url) {
            // Hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang t·∫£i audio
            button.innerHTML = '<i class="fas fa-download fa-pulse"></i>';
            button.title = 'ƒêang t·∫£i √¢m thanh...';

            // T·∫°o audio element
            currentAudio = new Audio(response.audio_data_url);
            currentTTSButton = button;

            // S·ª± ki·ªán khi audio s·∫µn s√†ng ph√°t
            currentAudio.addEventListener('canplaythrough', () => {
                button.innerHTML = '<i class="fas fa-play"></i>';
                button.title = 'ƒêang ph√°t √¢m thanh - Click ƒë·ªÉ d·ª´ng';
            });

            // S·ª± ki·ªán khi audio b·∫Øt ƒë·∫ßu ph√°t
            currentAudio.addEventListener('play', () => {
                button.innerHTML = '<i class="fas fa-pause"></i>';
                button.title = 'ƒêang ph√°t √¢m thanh - Click ƒë·ªÉ d·ª´ng';
            });

            // S·ª± ki·ªán khi audio k·∫øt th√∫c
            currentAudio.addEventListener('ended', () => {
                button.innerHTML = '<i class="fas fa-volume-up"></i>';
                button.disabled = false;
                button.title = 'Ph√°t audio';
                currentAudio = null;
                currentTTSButton = null;
            });

            // S·ª± ki·ªán khi c√≥ l·ªói ph√°t audio
            currentAudio.addEventListener('error', (e) => {
                button.innerHTML = '<i class="fas fa-exclamation-triangle"></i>';
                button.disabled = false;
                button.title = 'L·ªói ph√°t audio - Click ƒë·ªÉ th·ª≠ l·∫°i';
                currentAudio = null;
                currentTTSButton = null;
                console.error('Error playing audio:', e);
            });

            // B·∫Øt ƒë·∫ßu ph√°t audio
            try {
                await currentAudio.play();
                button.disabled = false;  // Cho ph√©p click ƒë·ªÉ d·ª´ng
            } catch (playError) {
                throw new Error('Kh√¥ng th·ªÉ ph√°t audio: ' + playError.message);
            }
            
        } else {
            throw new Error(response.detail || 'Kh√¥ng th·ªÉ t·∫°o audio');
        }

    } catch (error) {
        console.error('Error generating TTS:', error);
        button.innerHTML = '<i class="fas fa-exclamation-triangle"></i>';
        button.disabled = false;
        button.title = 'L·ªói - Click ƒë·ªÉ th·ª≠ l·∫°i';
        
        // Reset state
        currentAudio = null;
        currentTTSButton = null;
        
        // Hi·ªÉn th·ªã th√¥ng b√°o l·ªói nh·∫π nh√†ng
        const errorMsg = error.message || 'Kh√¥ng th·ªÉ ph√°t audio';
        console.warn('TTS Error:', errorMsg);
        
        // T·ª± ƒë·ªông reset v·ªÅ tr·∫°ng th√°i ban ƒë·∫ßu sau 3 gi√¢y
        setTimeout(() => {
            if (button && button.innerHTML.includes('exclamation-triangle')) {
                button.innerHTML = '<i class="fas fa-volume-up"></i>';
                button.title = 'Ph√°t audio';
            }
        }, 3000);
    }
}

async function playTextAsAudioMMS(text, event) {
    // NgƒÉn ch·∫∑n default action v√† event propagation
    if (event) {
        event.preventDefault();
        event.stopPropagation();
        event.stopImmediatePropagation();
    }
    
    const { api } = window.__APP__;
    
    // T√¨m button ƒë∆∞·ª£c click (event target)
    const button = event ? event.target.closest('.mms-tts-button') : null;
    if (!button) return;

    // N·∫øu ƒëang ph√°t audio n√†y, th√¨ d·ª´ng
    if (currentAudio && currentTTSButton === button) {
        currentAudio.pause();
        currentAudio = null;
        currentTTSButton = null;
        button.innerHTML = '<i class="fas fa-volume-up"></i>';
        button.disabled = false;
        button.title = 'Ph√°t audio (Facebook MMS-TTS-VIE)';
        return;
    }

    // D·ª´ng audio kh√°c n·∫øu ƒëang ph√°t
    if (currentAudio && currentTTSButton) {
        currentAudio.pause();
        currentAudio = null;
        currentTTSButton.innerHTML = currentTTSButton.classList.contains('mms-tts-button') ? 
            '<i class="fas fa-volume-up"></i>' : '<i class="fas fa-volume-up"></i>';
        currentTTSButton.disabled = false;
        currentTTSButton.title = currentTTSButton.classList.contains('mms-tts-button') ? 
            'Ph√°t audio (Facebook MMS-TTS-VIE)' : 'Ph√°t audio (Azure)';
    }

    try {
        // Hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang t·∫°o audio
        button.innerHTML = '<i class="fas fa-circle-notch fa-spin"></i>';
        button.disabled = true;
        button.title = 'ƒêang t·∫°o √¢m thanh (Facebook)...';

        // G·ªçi API ƒë·ªÉ t·∫°o audio
        const response = await api('/api/mms-tts/generate', {
            method: 'POST',
            body: JSON.stringify({ text: text }),
            noLoading: true  // Kh√¥ng hi·ªÉn th·ªã loading global
        });

        if (response.success && response.audio_data_url) {
            // Hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang t·∫£i audio
            button.innerHTML = '<i class="fas fa-download fa-pulse"></i>';
            button.title = 'ƒêang t·∫£i √¢m thanh...';

            // T·∫°o audio element
            currentAudio = new Audio(response.audio_data_url);
            currentTTSButton = button;

            // S·ª± ki·ªán khi audio s·∫µn s√†ng ph√°t
            currentAudio.addEventListener('canplaythrough', () => {
                button.innerHTML = '<i class="fas fa-play"></i>';
                button.title = 'ƒêang ph√°t √¢m thanh - Click ƒë·ªÉ d·ª´ng';
            });

            // S·ª± ki·ªán khi audio b·∫Øt ƒë·∫ßu ph√°t
            currentAudio.addEventListener('play', () => {
                button.innerHTML = '<i class="fas fa-pause"></i>';
                button.title = 'ƒêang ph√°t √¢m thanh - Click ƒë·ªÉ d·ª´ng';
            });

            // S·ª± ki·ªán khi audio k·∫øt th√∫c
            currentAudio.addEventListener('ended', () => {
                button.innerHTML = '<i class="fas fa-volume-up"></i>';
                button.disabled = false;
                button.title = 'Ph√°t audio (Facebook MMS-TTS-VIE)';
                currentAudio = null;
                currentTTSButton = null;
            });

            // S·ª± ki·ªán khi c√≥ l·ªói ph√°t audio
            currentAudio.addEventListener('error', (e) => {
                button.innerHTML = '<i class="fas fa-exclamation-triangle"></i>';
                button.disabled = false;
                button.title = 'L·ªói ph√°t audio - Click ƒë·ªÉ th·ª≠ l·∫°i';
                currentAudio = null;
                currentTTSButton = null;
                console.error('Error playing audio:', e);
            });

            // B·∫Øt ƒë·∫ßu ph√°t audio
            try {
                await currentAudio.play();
                button.disabled = false;  // Cho ph√©p click ƒë·ªÉ d·ª´ng
            } catch (playError) {
                throw new Error('Kh√¥ng th·ªÉ ph√°t audio: ' + playError.message);
            }
            
        } else {
            throw new Error(response.detail || 'Kh√¥ng th·ªÉ t·∫°o audio');
        }

    } catch (error) {
        console.error('Error generating MMS-TTS:', error);
        button.innerHTML = '<i class="fas fa-exclamation-triangle"></i>';
        button.disabled = false;
        button.title = 'L·ªói - Click ƒë·ªÉ th·ª≠ l·∫°i';
        
        // Reset state
        currentAudio = null;
        currentTTSButton = null;
        
        // Hi·ªÉn th·ªã th√¥ng b√°o l·ªói nh·∫π nh√†ng
        const errorMsg = error.message || 'Kh√¥ng th·ªÉ ph√°t audio';
        console.warn('MMS-TTS Error:', errorMsg);
        
        // T·ª± ƒë·ªông reset v·ªÅ tr·∫°ng th√°i ban ƒë·∫ßu sau 3 gi√¢y
        setTimeout(() => {
            if (button && button.innerHTML.includes('exclamation-triangle')) {
                button.innerHTML = '<i class="fas fa-volume-up"></i>';
                button.title = 'Ph√°t audio (Facebook MMS-TTS-VIE)';
            }
        }, 3000);
    }
}

// Voice Chat Functions
// Press & Hold functions
function startPressToTalk() {
    if (isPressedDown || isRecording) return;
    
    console.log('Press-to-talk started');
    isPressedDown = true;
    
    const voiceButton = document.getElementById('voice-button');
    const chatInput = document.getElementById('chat-input');
    
    // Visual feedback
    voiceButton.classList.add('voice-active', 'recording');
    voiceButton.innerHTML = '<i class="fas fa-microphone"></i>';
    voiceButton.title = 'ƒêang ghi √¢m... Th·∫£ ra ƒë·ªÉ g·ª≠i';
    
    // Show recording status
    if (chatInput) {
        chatInput.placeholder = 'ƒêang ghi √¢m... Th·∫£ n√∫t ƒë·ªÉ g·ª≠i';
    }
    
    // Start recording immediately
    startRecording();
}

function stopPressToTalk() {
    if (!isPressedDown) return;
    
    console.log('Press-to-talk stopped');
    isPressedDown = false;
    
    // Stop recording first
    if (isRecording) {
        stopRecording();
    }
    
    // UI will be reset in stopRecording(), but ensure it's reset here too
    setTimeout(() => {
        const voiceButton = document.getElementById('voice-button');
        const chatInput = document.getElementById('chat-input');
        const sendButton = document.getElementById('send-button');
        
        // Reset visual
        if (voiceButton) {
            voiceButton.classList.remove('voice-active', 'recording');
            voiceButton.innerHTML = '<i class="fas fa-microphone-slash"></i>';
            voiceButton.title = '·∫§n ƒë√® ƒë·ªÉ ghi √¢m';
        }
        
        if (sendButton) {
            sendButton.innerHTML = '<i class="fas fa-paper-plane"></i>';
            sendButton.classList.remove('recording');
            sendButton.title = 'G·ª≠i tin nh·∫Øn';
        }
        
        if (chatInput) {
            chatInput.placeholder = 'Nh·∫≠p tin nh·∫Øn ho·∫∑c ·∫•n ƒë√® n√∫t mic ƒë·ªÉ ghi √¢m...';
        }
    }, 100); // Small delay to ensure stopRecording completes
}

async function startRecording() {
    if (isRecording) {
        stopRecording();
        return;
    }

    try {
        console.log('üé§ Starting Web Audio API recording...');
        
        // Ki·ªÉm tra browser support
        if (!navigator.mediaDevices || !navigator.mediaDevices.getUserMedia) {
            throw new Error('Browser kh√¥ng h·ªó tr·ª£ ghi √¢m');
        }
        
        // ∆Øu ti√™n Web Audio API cho quality t·ªët h∆°n
        if (!window.AudioContext && !window.webkitAudioContext) {
            throw new Error('Browser kh√¥ng h·ªó tr·ª£ Web Audio API');
        }
        
        // Xin quy·ªÅn microphone v·ªõi settings t·ªëi ∆∞u cho Azure Speech
        console.log('Requesting microphone permission...');
        const stream = await navigator.mediaDevices.getUserMedia({ 
            audio: {
                sampleRate: 16000,  // Fixed 16kHz cho Azure
                channelCount: 1,
                echoCancellation: true,
                noiseSuppression: true,
                autoGainControl: true
            } 
        });
        
        console.log('‚úÖ Microphone access granted');
        
        // T·∫°o AudioContext v√† setup Web Audio API recording
        const audioContext = new (window.AudioContext || window.webkitAudioContext)({
            sampleRate: 16000  // Force 16kHz
        });
        
        const source = audioContext.createMediaStreamSource(stream);
        
        // S·ª≠ d·ª•ng ScriptProcessorNode ƒë·ªÉ capture raw audio data
        const bufferSize = 4096;
        const recorder = audioContext.createScriptProcessor(bufferSize, 1, 1);
        
        // Store audio data
        window.recordedData = [];
        window.recordingStream = stream;
        window.audioContext = audioContext;
        window.audioRecorder = recorder;
        
        recorder.onaudioprocess = (event) => {
            const inputBuffer = event.inputBuffer;
            const inputData = inputBuffer.getChannelData(0);
            
            // Copy data (Float32Array)
            const buffer = new Float32Array(inputData.length);
            buffer.set(inputData);
            window.recordedData.push(buffer);
            
            console.log(`üìä Audio chunk: ${inputData.length} samples`);
        };
        
        // Connect audio nodes
        source.connect(recorder);
        recorder.connect(audioContext.destination);
        
        console.log('‚úÖ Web Audio API recording started');
        isRecording = true;

    } catch (error) {
        console.error('Error starting recording:', error);
        alert('Kh√¥ng th·ªÉ truy c·∫≠p microphone. Vui l√≤ng cho ph√©p quy·ªÅn truy c·∫≠p microphone.');
    }
}

function stopRecording() {
    if (!isRecording) return;
    
    console.log('üõë Stopping Web Audio API recording...');
    
    try {
        // Disconnect audio nodes
        if (window.audioRecorder) {
            window.audioRecorder.disconnect();
        }
        
        // Stop audio context
        if (window.audioContext) {
            window.audioContext.close();
        }
        
        // Stop stream
        if (window.recordingStream) {
            window.recordingStream.getTracks().forEach(track => track.stop());
        }
        
        isRecording = false;
        
        // Reset UI buttons
        const voiceButton = document.getElementById('voice-button');
        const sendButton = document.getElementById('send-button');
        
        if (voiceButton) {
            voiceButton.classList.remove('voice-active', 'recording');
            voiceButton.innerHTML = '<i class="fas fa-microphone-slash"></i>';
            voiceButton.title = '·∫§n ƒë√® ƒë·ªÉ ghi √¢m';
        }
        
        if (sendButton) {
            sendButton.innerHTML = '<i class="fas fa-paper-plane"></i>';
            sendButton.classList.remove('recording');
            sendButton.title = 'G·ª≠i tin nh·∫Øn';
        }
        
        // Reset chat input placeholder
        const chatInput = document.getElementById('chat-input');
        if (chatInput) {
            chatInput.placeholder = 'Nh·∫≠p tin nh·∫Øn ho·∫∑c ·∫•n ƒë√® n√∫t mic ƒë·ªÉ ghi √¢m...';
        }
        
        // Process recorded data
        if (window.recordedData && window.recordedData.length > 0) {
            console.log(`üìä Processing ${window.recordedData.length} audio chunks...`);
            
            // Combine all chunks
            const totalLength = window.recordedData.reduce((sum, chunk) => sum + chunk.length, 0);
            const combinedData = new Float32Array(totalLength);
            
            let offset = 0;
            for (const chunk of window.recordedData) {
                combinedData.set(chunk, offset);
                offset += chunk.length;
            }
            
            console.log(`üéµ Total samples: ${totalLength}, Duration: ${(totalLength / 16000).toFixed(2)}s`);
            
            // Convert to WAV
            const wavBlob = createWavBlob(combinedData, 16000);
            console.log(`üíæ Created WAV blob: ${wavBlob.size} bytes`);
            
            // Clean up
            window.recordedData = [];
            
            // Process the WAV
            processRecordedWav(wavBlob);
        } else {
            console.error('‚ùå No audio data recorded');
        }
        
    } catch (error) {
        console.error('Error stopping recording:', error);
        isRecording = false;
        
        // Reset UI on error
        const voiceButton = document.getElementById('voice-button');
        const sendButton = document.getElementById('send-button');
        const chatInput = document.getElementById('chat-input');
        
        if (voiceButton) {
            voiceButton.classList.remove('voice-active', 'recording');
            voiceButton.innerHTML = '<i class="fas fa-microphone-slash"></i>';
            voiceButton.title = '·∫§n ƒë√® ƒë·ªÉ ghi √¢m';
        }
        
        if (sendButton) {
            sendButton.innerHTML = '<i class="fas fa-paper-plane"></i>';
            sendButton.classList.remove('recording');
            sendButton.title = 'G·ª≠i tin nh·∫Øn';
        }
        
        if (chatInput) {
            chatInput.placeholder = 'Nh·∫≠p tin nh·∫Øn ho·∫∑c ·∫•n ƒë√® n√∫t mic ƒë·ªÉ ghi √¢m...';
        }
    }
}

// WAV Creation Functions
function createWavBlob(audioData, sampleRate) {
    const length = audioData.length;
    const buffer = new ArrayBuffer(44 + length * 2);
    const view = new DataView(buffer);
    
    // WAV header
    const writeString = (offset, string) => {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, 36 + length * 2, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);  // PCM
    view.setUint16(22, 1, true);  // Mono
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, sampleRate * 2, true);
    view.setUint16(32, 2, true);
    view.setUint16(34, 16, true);
    writeString(36, 'data');
    view.setUint32(40, length * 2, true);
    
    // Convert float32 to int16
    let offset = 44;
    for (let i = 0; i < length; i++) {
        const sample = Math.max(-1, Math.min(1, audioData[i]));
        view.setInt16(offset, sample * 0x7FFF, true);
        offset += 2;
    }
    
    return new Blob([buffer], { type: 'audio/wav' });
}

async function processRecordedWav(wavBlob) {
    console.log('üéµ Processing recorded WAV for immediate send...');
    
    try {
        // Quick audio validation
        const isValid = await testAudioPlayback(wavBlob);
        
        if (isValid) {
            console.log('‚úÖ WAV audio valid, sending immediately...');
            // Send directly without preview
            await processVoiceInput(wavBlob);
        } else {
            console.error('WAV audio kh√¥ng h·ª£p l·ªá');
            alert('WAV audio ghi ƒë∆∞·ª£c c√≥ v·∫•n ƒë·ªÅ. Vui l√≤ng th·ª≠ l·∫°i.');
        }
    } catch (error) {
        console.error('Error processing WAV:', error);
        alert('L·ªói x·ª≠ l√Ω audio WAV: ' + error.message);
    }
}

// Audio testing and playback utilities
// Quick audio validation (simplified for immediate send)
async function testAudioPlayback(audioBlob) {
    console.log('üîç Quick audio validation...');
    
    // Basic checks
    if (!audioBlob || audioBlob.size === 0) {
        console.error('‚ùå Empty audio blob');
        return false;
    }
    
    if (audioBlob.size < 1000) { // Less than 1KB is probably too small
        console.warn('‚ö†Ô∏è Audio blob very small:', audioBlob.size, 'bytes');
        return false;
    }
    
    console.log('‚úÖ Audio blob seems valid:', audioBlob.size, 'bytes');
    return true;
}

// Audio conversion utility (not used anymore - direct WAV recording)
async function convertToWav(audioBlob) {
    return new Promise((resolve, reject) => {
        const audioContext = new (window.AudioContext || window.webkitAudioContext)();
        const fileReader = new FileReader();
        
        fileReader.onload = async function(e) {
            try {
                const arrayBuffer = e.target.result;
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                
                // Convert to WAV
                const wavBuffer = audioBufferToWav(audioBuffer);
                const wavBlob = new Blob([wavBuffer], { type: 'audio/wav' });
                
                resolve(wavBlob);
            } catch (error) {
                reject(error);
            }
        };
        
        fileReader.onerror = () => reject(new Error('Failed to read audio file'));
        fileReader.readAsArrayBuffer(audioBlob);
    });
}

function audioBufferToWav(buffer) {
    const length = buffer.length;
    const numberOfChannels = buffer.numberOfChannels;
    const sampleRate = buffer.sampleRate;
    const bytesPerSample = 2;
    const blockAlign = numberOfChannels * bytesPerSample;
    const byteRate = sampleRate * blockAlign;
    const dataSize = length * blockAlign;
    const bufferSize = 44 + dataSize;
    
    const arrayBuffer = new ArrayBuffer(bufferSize);
    const view = new DataView(arrayBuffer);
    
    // WAV header
    const writeString = (offset, string) => {
        for (let i = 0; i < string.length; i++) {
            view.setUint8(offset + i, string.charCodeAt(i));
        }
    };
    
    writeString(0, 'RIFF');
    view.setUint32(4, bufferSize - 8, true);
    writeString(8, 'WAVE');
    writeString(12, 'fmt ');
    view.setUint32(16, 16, true);
    view.setUint16(20, 1, true);
    view.setUint16(22, numberOfChannels, true);
    view.setUint32(24, sampleRate, true);
    view.setUint32(28, byteRate, true);
    view.setUint16(32, blockAlign, true);
    view.setUint16(34, bytesPerSample * 8, true);
    writeString(36, 'data');
    view.setUint32(40, dataSize, true);
    
    // Convert audio data
    let offset = 44;
    for (let i = 0; i < length; i++) {
        for (let channel = 0; channel < numberOfChannels; channel++) {
            const sample = Math.max(-1, Math.min(1, buffer.getChannelData(channel)[i]));
            view.setInt16(offset, sample * 0x7FFF, true);
            offset += 2;
        }
    }
    
    return arrayBuffer;
}

async function processVoiceInput(audioBlob) {
    const messagesContainer = document.getElementById('chat-messages');
    const typingIndicator = document.getElementById('typing-indicator');

    try {
        // Hi·ªÉn th·ªã tr·∫°ng th√°i ƒëang x·ª≠ l√Ω v·ªõi animation
        typingIndicator.style.display = 'block';
        typingIndicator.innerHTML = '<small><i class="fas fa-microphone-alt fa-pulse"></i> ƒêang nh·∫≠n di·ªán gi·ªçng n√≥i...</small>';

        // Process voice recognition
        const result = await processVoiceRecognition(audioBlob);
        await handleVoiceResult(result, messagesContainer, typingIndicator);
        
    } catch (error) {
        console.error('Voice processing error:', error);
        
        // Th√¥ng b√°o l·ªói v·ªõi h∆∞·ªõng d·∫´n c·ª• th·ªÉ
        let errorContent = 'Xin l·ªói, t√¥i kh√¥ng th·ªÉ nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i c·ªßa b·∫°n.';
        
        if (error.message.includes('audio')) {
            errorContent += '\n\nüí° H∆∞·ªõng d·∫´n:\n‚Ä¢ Ki·ªÉm tra microphone ƒë√£ b·∫≠t ch∆∞a\n‚Ä¢ N√≥i r√µ r√†ng v√† to h∆°n\n‚Ä¢ Ghi √¢m t·ª´ 1-3 gi√¢y';
        } else if (error.message.includes('nh·∫≠n di·ªán')) {
            errorContent += '\n\nüí° C√≥ th·ªÉ th·ª≠:\n‚Ä¢ N√≥i ch·∫≠m h∆°n v√† r√µ r√†ng\n‚Ä¢ Ki·ªÉm tra √¢m l∆∞·ª£ng microphone\n‚Ä¢ Ho·∫∑c g√µ tin nh·∫Øn b√¨nh th∆∞·ªùng';
        }
        
        const errorMessage = {
            role: 'assistant', 
            content: errorContent,
            message_type: 'text',
            timestamp: new Date().toISOString()
        };
        const errorMessageEl = createMessageElement(errorMessage);
        messagesContainer.appendChild(errorMessageEl);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
    } finally {
        typingIndicator.style.display = 'none';
    }
}

async function processVoiceRecognition(audioBlob) {
    const { api } = window.__APP__;
    
    // Debug: Ki·ªÉm tra audio blob
    console.log('Audio blob size:', audioBlob.size, 'bytes');
    console.log('Audio blob type:', audioBlob.type);
    
    if (audioBlob.size === 0) {
        throw new Error('Kh√¥ng c√≥ d·ªØ li·ªáu audio ƒë·ªÉ g·ª≠i');
    }
    
    // Azure Speech Service h·ªó tr·ª£ WebM, kh√¥ng c·∫ßn convert
    let processedBlob = audioBlob;
    let filename = 'voice_input.webm';
    
    // Note: ƒê√£ test - Azure Speech Service ho·∫°t ƒë·ªông t·ªët v·ªõi WebM
    console.log('Using original WebM format (Azure supports it)');

    // Th·ª≠ c√°ch ti·∫øp c·∫≠n FormData tr∆∞·ªõc
    try {
        const formData = new FormData();
        formData.append('audio_file', processedBlob, filename);
        
        // Debug: Ki·ªÉm tra FormData
        console.log('FormData entries:');
        for (let [key, value] of formData.entries()) {
            console.log(`${key}:`, value);
            if (value instanceof File || value instanceof Blob) {
                console.log(`  - Size: ${value.size} bytes`);
                console.log(`  - Type: ${value.type}`);
                console.log(`  - Name: ${value.name || 'unnamed'}`);
            }
        }

        // G·ª≠i audio ƒë·ªÉ nh·∫≠n di·ªán - s·ª≠ d·ª•ng fetch tr·ª±c ti·∫øp v·ªõi FormData
        const authToken = window.__APP__.authToken || localStorage.getItem('auth_token');
        console.log('Auth token:', authToken ? 'Present' : 'Missing');
        const response = await fetch('/api/speech/recognize', {
            method: 'POST',
            headers: {
                'Authorization': `Bearer ${authToken}`
            },
            body: formData
        });
        
        if (!response.ok) {
            const errorData = await response.json().catch(() => ({}));
            throw new Error(errorData.detail || `HTTP ${response.status}`);
        }
        
        const result = await response.json();
        
        return result;
        
    } catch (formDataError) {
        console.warn('FormData approach failed:', formDataError);
        
        // Fallback: Chuy·ªÉn sang base64 approach
        console.log('Trying base64 approach...');
        
        const base64Audio = await new Promise((resolve, reject) => {
            const reader = new FileReader();
            reader.onload = () => resolve(reader.result.split(',')[1]);
            reader.onerror = reject;
            reader.readAsDataURL(processedBlob); // S·ª≠ d·ª•ng processed blob (c√≥ th·ªÉ ƒë√£ convert WAV)
        });
        
        const result = await api('/api/speech/recognize-base64', {
            method: 'POST',
            body: JSON.stringify({
                audio_data: base64Audio,
                mime_type: processedBlob.type || audioBlob.type // S·ª≠ d·ª•ng type c·ªßa processed blob
            }),
            noLoading: true
        });
        
        return result;
    }
}

async function handleVoiceResult(result, messagesContainer, typingIndicator) {
    const { api } = window.__APP__;
    
    try {
        if (result.success && result.text.trim()) {
            // Hi·ªÉn th·ªã tin nh·∫Øn user (voice)
            // Debug recognition result
            console.log('üé§ Recognition result:', result.text);
            if (result.confidence) {
                console.log('üéØ Confidence:', result.confidence);
            }
            
            // Show warning for potentially incorrect recognition
            let displayText = result.text;
            if (result.text.length < 3 || result.text === 'Ph·∫©y.' || result.text === '.') {
                displayText = `${result.text} ‚ö†Ô∏è (c√≥ th·ªÉ nh·∫≠n di·ªán sai)`;
            }
            
            const userMessage = {
                role: 'user',
                content: displayText,
                message_type: 'text',
                timestamp: new Date().toISOString(),
                metadata: { 
                    voice_input: true,
                    original_recognition: result.text,
                    confidence: result.confidence || null
                }
            };
            
            const userMessageEl = createMessageElement(userMessage);
            messagesContainer.appendChild(userMessageEl);
            messagesContainer.scrollTop = messagesContainer.scrollHeight;

            // G·ª≠i tin nh·∫Øn v·ªõi auto-play enabled
            typingIndicator.innerHTML = '<small><i class="fas fa-robot fa-pulse"></i> Tr·ª£ l√Ω ƒëang tr·∫£ l·ªùi...</small>';
            
            const chatResponse = await api(`/api/chats/${currentSessionId}/messages`, {
                method: 'POST',
                body: JSON.stringify({ 
                    content: result.text, 
                    message_type: 'text', // S·ª≠ d·ª•ng 'text' type, ƒë√°nh d·∫•u b·∫±ng metadata
                    auto_play_response: true  // T·ª± ƒë·ªông ph√°t audio
                }),
                noLoading: true
            });

            // Hi·ªÉn th·ªã AI response
            const aiMessage = {
                role: 'assistant',
                content: chatResponse.ai_response,
                message_type: 'text',
                timestamp: new Date().toISOString()
            };
            
            const aiMessageEl = createMessageElement(aiMessage);
            messagesContainer.appendChild(aiMessageEl);
            messagesContainer.scrollTop = messagesContainer.scrollHeight;

            // T·ª± ƒë·ªông ph√°t audio n·∫øu c√≥
            if (chatResponse.auto_play_audio) {
                try {
                    typingIndicator.innerHTML = '<small><i class="fas fa-volume-up fa-pulse"></i> ƒêang ph√°t √¢m thanh...</small>';
                    
                    const autoAudio = new Audio(chatResponse.auto_play_audio);
                    
                    autoAudio.onended = () => {
                        typingIndicator.style.display = 'none';
                    };
                    
                    autoAudio.onerror = () => {
                        typingIndicator.style.display = 'none';
                    };
                    
                    await autoAudio.play();
                } catch (playError) {
                    console.warn('Auto-play failed:', playError);
                    typingIndicator.style.display = 'none';
                }
            } else {
                typingIndicator.style.display = 'none';
            }

            // Reload profile data if needed
            if (window.__APP__ && window.__APP__.loadCurrentProfile) {
                try {
                    await window.__APP__.loadCurrentProfile();
                } catch (e) {
                    console.warn('Failed to refresh profile data:', e);
                }
            }

        } else {
            throw new Error(result.error || 'Kh√¥ng th·ªÉ nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i');
        }

    } catch (error) {
        console.error('Voice processing error:', error);
        
        // Hi·ªÉn th·ªã th√¥ng b√°o l·ªói
        const errorMessage = {
            role: 'assistant',
            content: 'Xin l·ªói, t√¥i kh√¥ng th·ªÉ nh·∫≠n di·ªán ƒë∆∞·ª£c gi·ªçng n√≥i c·ªßa b·∫°n. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c g√µ tin nh·∫Øn.',
            message_type: 'text',
            timestamp: new Date().toISOString()
        };
        const errorMessageEl = createMessageElement(errorMessage);
        messagesContainer.appendChild(errorMessageEl);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
    } finally {
        typingIndicator.style.display = 'none';
    }
}

let selectedImageData = null;

function setupChatEventListeners() {
    const chatInput = document.getElementById('chat-input');
    const sendButton = document.getElementById('send-button');
    const imageButton = document.getElementById('image-button');
    const imageUpload = document.getElementById('image-upload');
    const removeImageButton = document.getElementById('remove-image');
    const chatForm = document.getElementById('chat-form');

    // Kh√¥ng c√≤n form submit; ch·∫∑n Enter ·ªü c·∫•p t√†i li·ªáu khi focus ·ªü input
    document.addEventListener('keydown', (e) => {
        if (e.key === 'Enter' && document.activeElement && document.activeElement.id === 'chat-input' && !e.shiftKey) {
            e.preventDefault();
            e.stopPropagation();
            sendMessage();
        }
    }, true);

    // Enter trong input (kh√¥ng Shift) s·∫Ω g·ª≠i
    if (chatInput) {
        chatInput.addEventListener('keydown', (e) => {
            if (e.key === 'Enter' && !e.shiftKey) {
                e.preventDefault();
                e.stopPropagation();
                sendMessage();
            }
        });
    }

    // Click g·ª≠i - ch·ªâ cho text message
    if (sendButton) {
        sendButton.addEventListener('click', (event) => {
            event.preventDefault();
            event.stopPropagation();
            sendMessage();
        });
    }

    // Voice button - Press & Hold
    const voiceButton = document.getElementById('voice-button');
    if (voiceButton) {
        // Mouse events
        voiceButton.addEventListener('mousedown', (event) => {
            event.preventDefault();
            startPressToTalk();
        });
        
        voiceButton.addEventListener('mouseup', (event) => {
            event.preventDefault();
            stopPressToTalk();
        });
        
        voiceButton.addEventListener('mouseleave', (event) => {
            // Stop recording if mouse leaves button while pressed
            if (isPressedDown) {
                stopPressToTalk();
            }
        });
        
        // Touch events for mobile
        voiceButton.addEventListener('touchstart', (event) => {
            event.preventDefault();
            startPressToTalk();
        });
        
        voiceButton.addEventListener('touchend', (event) => {
            event.preventDefault();
            stopPressToTalk();
        });
        
        voiceButton.addEventListener('touchcancel', (event) => {
            // Stop if touch is cancelled
            if (isPressedDown) {
                stopPressToTalk();
            }
        });
    }

    // Image upload functionality
    if (imageButton && imageUpload) {
        imageButton.addEventListener('click', () => {
            imageUpload.click();
        });

        imageUpload.addEventListener('change', handleImageUpload);
    }

    if (removeImageButton) {
        removeImageButton.addEventListener('click', removeSelectedImage);
    }
}

function handleImageUpload(event) {
    const file = event.target.files[0];
    if (!file) return;

    // Validate file type
    if (!file.type.startsWith('image/')) {
        alert('Vui l√≤ng ch·ªçn file ·∫£nh');
        return;
    }

    // Validate file size (max 5MB)
    if (file.size > 5 * 1024 * 1024) {
        alert('K√≠ch th∆∞·ªõc ·∫£nh qu√° l·ªõn. Vui l√≤ng ch·ªçn ·∫£nh nh·ªè h∆°n 5MB');
        return;
    }

    const reader = new FileReader();
    reader.onload = (e) => {
        const base64Data = e.target.result.split(',')[1]; // Remove data:image/...;base64, prefix
        selectedImageData = base64Data;

        // Show preview
        const previewContainer = document.getElementById('image-preview');
        const previewImage = document.getElementById('preview-image');

        previewImage.src = e.target.result;
        previewContainer.style.display = 'block';

        // Clear file input for next use
        event.target.value = '';
        resizeChatLayout();
    };

    reader.readAsDataURL(file);
}

function removeSelectedImage() {
    selectedImageData = null;
    const previewContainer = document.getElementById('image-preview');
    previewContainer.style.display = 'none';
    resizeChatLayout();
}

async function sendMessage() {
    const chatInput = document.getElementById('chat-input');
    const sendButton = document.getElementById('send-button');
    const typingIndicator = document.getElementById('typing-indicator');
    const messagesContainer = document.getElementById('chat-messages');

    if (!chatInput || !sendButton || !currentSessionId) return;

    const message = chatInput.value.trim();
    if (!message && !selectedImageData) return;

    try {
        // Disable input
        chatInput.disabled = true;
        sendButton.disabled = true;
        typingIndicator.style.display = 'block';
        typingIndicator.innerHTML = '<small><i class="fas fa-circle-notch fa-spin"></i> Tr·ª£ l√Ω ƒëang tr·∫£ l·ªùi...</small>';

        // Clear input
        chatInput.value = '';

        // Local echo: user message
        const userMessage = {
            role: 'user',
            content: message,
            message_type: (selectedImageData ? 'image' : 'text'),
            timestamp: new Date().toISOString()
        };
        if (selectedImageData) {
            userMessage.metadata = { has_image: true, image_data: selectedImageData };
        }
        const userMessageEl = createMessageElement(userMessage);
        messagesContainer.appendChild(userMessageEl);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;

        // Prepare request
        const { api } = window.__APP__;
        const requestData = { content: message, message_type: userMessage.message_type };
        if (userMessage.message_type === 'image') requestData.image_data = userMessage.metadata.image_data;

        // Clear selected image after sending (UI)
        if (selectedImageData) removeSelectedImage();

        // Send to API
        const response = await api(`/api/chats/${currentSessionId}/messages`, {
            method: 'POST',
            body: JSON.stringify(requestData),
            noLoading: true
        });

        // AI response
        const aiMessage = {
            role: 'assistant',
            content: response.ai_response,
            message_type: 'text',
            timestamp: new Date().toISOString()
        };
        const aiMessageEl = createMessageElement(aiMessage);
        messagesContainer.appendChild(aiMessageEl);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;

        chatMessages.push(userMessage, aiMessage);
        
        // Reload current profile data in case AI updated health status
        if (window.__APP__ && window.__APP__.loadCurrentProfile) {
            try {
                await window.__APP__.loadCurrentProfile();
                console.log('Profile data refreshed after chat update');
            } catch (e) {
                console.warn('Failed to refresh profile data:', e);
            }
        }
    } catch (error) {
        console.error('Error sending message:', error);
        const errorMessage = {
            role: 'assistant',
            content: 'Xin l·ªói, c√≥ l·ªói x·∫£y ra khi x·ª≠ l√Ω tin nh·∫Øn. Vui l√≤ng th·ª≠ l·∫°i.',
            message_type: 'text',
            timestamp: new Date().toISOString()
        };
        const errorMessageEl = createMessageElement(errorMessage);
        messagesContainer.appendChild(errorMessageEl);
        messagesContainer.scrollTop = messagesContainer.scrollHeight;
    } finally {
        chatInput.disabled = false;
        sendButton.disabled = false;
        typingIndicator.style.display = 'none';
        chatInput.focus();
        resizeChatLayout();
    }
}